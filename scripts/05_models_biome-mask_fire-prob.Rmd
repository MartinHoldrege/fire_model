---
title: "Models of fire probability for the sagebrush biome"
author: "Martin Holdrege"
date: "`r lubridate::today()`"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, cache.lazy = FALSE)
```

# Dependencies 

Sourcing the script that creates a dataframe of historical
fore occurrence, as well as biotic and climate
predictors for those same grid-cells. 

```{r source_data, warning=FALSE, message=FALSE, cache = TRUE}
source("scripts/04_create_biome-mask_dataframe.R")
```

```{r warning=FALSE, message=FALSE}
source("src/general_functions.R")
source("src/fig_params.R")
source("src/modeling_functions.R")
library(randomForest)
library(tidyverse)
library(margins) # for cplot()
library(GGally) # for ggpairs()
library(gnm) # generalized non-linear models
library(pdp) # for partial dependence plots
library(splines) # for ns() (splines) inside formulas of glm()
library(gridExtra)
library(knitr)
theme_set(theme_classic())
```


# Prep data

```{r prep_data, cache=TRUE}

# converting a fire count into a factor (true if at least 1 fire occured)
occur_factor <- function(nfire){
  factor(nfire > 0, levels = c("TRUE", "FALSE"))
}
dfs_biome3 <- map(dfs_biome2, function(df) {
  out <- df %>% 
  # probability of fire in a given year
    mutate(# number of years the mtbs count data corresponds to (for binomial glm)
           # all count datasets (mtbs and ifph) are 35 years (change if updated)
           mtbs_n = 36, 
           # proportion of years with fires
           mtbs_prop = nfire_mtbs/mtbs_n,
           ifph_prop = nfire_ifph/mtbs_n,
           comb_prop = nfire_comb/mtbs_n,
           lba_prop = nfire_lba/mtbs_n
           ) %>% 
    # creating true/false occurrence cols for each datasets
    mutate(across(matches("^nfire_"), .fns = list(occur = occur_factor),
                  .names = "{.fn}_{.col}")) %>% 
    rename_with(.fn = str_replace, .cols = matches("^occur_"),
                pattern = "_nfire", replacement = "")
})

method <- names(dfs_biome3)
names(method) <- method

# Create transformed variables
dfs_biome3 <- map(dfs_biome3, function(df) {
  df %>% 
    mutate(afgAGB_sqrt = sqrt(afgAGB),
           afgAGB_ln = log(afgAGB),
           prcpPropSum_exp = exp(prcpPropSum),
           prcpPropSum_sqrt = sqrt(prcpPropSum),
           prcpPropSum_sq = prcpPropSum^2,
           MAP_sqrt = sqrt(MAP))
})
```


## training data

Note--previously a small sample for now to make model fitting quicker.
Now the training dataset is all the data.

```{r train, dependson='prep_data', cache = TRUE}
set.seed(1234)
pred_vars <- c("afgAGB", "pfgAGB", "MAT", "MAP", "prcpPropSum")
names(pred_vars) <- pred_vars
# predictor vars are the same in both dfs
df_pred <- dfs_biome3[[1]][, pred_vars]
# n = 10000 # for testing
n = nrow(dfs_biome3[[1]]) # fit models on all the data
         
row_nums <- 1:nrow(dfs_biome3[[1]])
rows_train <- sample(row_nums, size = n, replace = FALSE)

# rows for test dataset
# note set up this way, in case the training
# dataset is all the data
rows2sample <- if(n == length(rows_train)) {
  row_nums
} else {
  row_nums[!row_nums %in% rows_train]
}

# rows used in testing dataset
rows_test <- sample(rows2sample, size = 40000, replace = FALSE)

# selecting rows this was so both dataframes in list have same rows
# and differences in models will only be b/ of differences in response

dfs_train <- map(dfs_biome3, function(df) as.data.frame(df[rows_train, ]))
dfs_test <- map(dfs_biome3, function(df) as.data.frame(df[rows_test, ]))

# all variables (transformed or not, that could be predictor vars)
all_pred_vars <- names(dfs_biome3[[1]]) %>% 
  str_subset(pattern = paste0("(", 
                              paste0(pred_vars, collapse = ")|("), 
                              ")")
             )
train_pred <- dfs_train[[1]][, all_pred_vars]
test_pred <- dfs_test[[1]][, all_pred_vars]
```

# Exploratory figs & summary values


```{r summary_table}

create_summary <- function(df) {
  df %>% 
    pivot_longer(cols = everything(),
                 names_to = 'variable') %>% 
    group_by(variable) %>% 
    summarise(across(value, .fns = list(mean = mean, min = min, 
                                        median = median, max = max))) %>% 
    mutate(across(where(is.numeric), round, 4))
}

df_pred %>% 
  create_summary() %>% 
  knitr::kable(caption = 'summaries of predictor variables')


response_summary <- map(dfs_biome3, function(df) {
  df %>% 
    dplyr::select(-all_of(pred_vars), -matches("^occur_")) %>% 
    create_summary()
})

kable(response_summary$paint, 
      caption = 'summaries of response variables, calculated using paint  <- ')

kable(response_summary$reduceToImage, 
      caption = 'summaries of response variables, calculated using reduceToImage method')

```

## Plot predictor vars against each other

here using pred dataframe, because smaller and this code is slow. 

```{r pred_v_pred, cache=TRUE, dependson='train'}
ggpairs(test_pred %>% select(-matches("_")),
        lower = list(continuous = GGally::wrap("points", alpha = 0.1,    size=0.2)))
```

## transformed pred vars

```{r pred_v_pred_transform, cache=TRUE, dependson='train'}

train_pred_trans <- test_pred %>% 
  mutate(afgAGB_sq = afgAGB^2,
         pfgAGB_sq = pfgAGB^2,
         MAT_exp = exp(MAT),
         MAP_sq = MAP^2,
         prcpPropSum_exp = exp(prcpPropSum))

train_pred_trans[, c("afgAGB_sq", "pfgAGB_sq", "MAT", "MAP_sq", "prcpPropSum_exp")] %>% 
  ggpairs(lower = list(continuous = GGally::wrap("points", alpha = 0.1,   
                                                 size=0.2)))
```

## boxplots-- # of fires vs predictor variables

```{r n_fires_boxplots, fig.height=9, fig.width=8, cache = TRUE, dependson='prep_data'}

# vectors of names of response variables
vars_nfire <- names(dfs_biome3[[1]]) %>% 
  str_subset("^nfire_")

vars_occur <- names(dfs_biome3[[1]]) %>% 
  str_subset("^occur_")

names(vars_occur) <- str_replace(vars_occur, "occur_", "")

vars_prop <- str_replace(vars_occur, "occur_", "") %>% 
  paste0(., "_prop")

names(vars_prop) <- names(vars_occur)

# longformat dataframes for making boxplots
dfs_biome_long <- map(dfs_biome3, function(df) {
  # for some reason select() was giving me problems
  predvars2long(df, response_vars = c(vars_nfire, vars_prop), 
                pred_vars = pred_vars) %>% 
    mutate(across(all_of(vars_nfire), factor))
})

fire_box <- function(xvar, df, method) {
  ggplot(df, aes_string(x= xvar, y = 'value')) +
    geom_boxplot() +
    facet_wrap(~name, scales = 'free_y') +
    labs(subtitle = paste0(xvar, " (", method, " method)"))
}

map2(dfs_biome_long, names(dfs_biome_long), function(df, method) {
  map(vars_nfire, fire_box, df = df, method = method)
})

  
```

## Dotplots: deciles vs fire probability

First calculating mean of response variables (proportion of years with fires) 
for each decile of each predictor
variable. 

Next plotting deciles (originally was deciles, 10 bins, now
actually 0.5 percentiles, i.e. 200 bins)
vs fire probability. Dotplots made for each predictor
variable and response variable (as well method by which response variable
was calculated)

```{r observed_deciles}

dfs_deciles1 <- map(dfs_biome_long, longdf2deciles, response_vars = vars_prop)
# df <- dfs_deciles1[[1]]
# yvar = vars_prop[[1]]

map2(dfs_deciles1, names(dfs_deciles1), function(df, method) {
  map(vars_prop, decile_dotplot, df = df, method = method,
      ylab = "mean observed fire probability (nfires/nyears)")
})

```


## Histograms of response vars

Histograms for all fire variables, includes all grid cells from sagebrush biome,
showing fire probability (nfires/nyears)

```{r hists_response, message = FALSE, warning = FALSE}

dfs_prop_long <- map(dfs_biome3, function(df) {
  df %>% 
    select(matches("_prop$")) %>% 
    pivot_longer(cols = everything(),
                 names_to = "variable",
                 values_to = 'value') %>% 
    mutate(probability = value*100)
})

map(method, function(x) {
  ggplot(dfs_prop_long[[x]], aes(probability)) +
  geom_histogram(breaks = seq(-1, 15)) +
  facet_wrap(~variable, scales = "free_y") +
  labs(x = lab_fireProbPerc,
       caption = paste(x, "method used")) +
  coord_cartesian(xlim = c(-0.1, 15))
})

```

## Plot response variables against each other

```{r response_ggpairs, cache=TRUE, dependson='train'}
map(method, function(x) {
  ggpairs(dfs_test[[x]] , title =  paste0('relationships between response variables (',
                           x,  " method used)"),
        columns = vars_nfire,
        lower = list(continuous = GGally::wrap("points", alpha = 0.1, size=0.2)))
})

```

# GLMs 


## fitting models

### fitting various transforms

Creating formulas where each variable on its own is transformed numerous ways
(including formula to fit spline), all other variables are left alone,
that repeated for each variable. So have models with 1 variable transformed,
2 transformed, etc. 

see documentation for glms_iterate_transforms, in the modelling_functions.R
script

```{r iterate_transform, warning = FALSE, dependson='train', cache = TRUE, cache.lazy = FALSE}
set.seed(1234)
mods_glm_mtbs1 <- glms_iterate_transforms(
  preds = pred_vars, 
  df = dfs_train$paint[ , ],
  response_var = "mtbs_prop", 
  delta_aic = 4)

# not including the last element of the list which is final_formula
mods_glm_mtbs2 <- mods_glm_mtbs1[-length(mods_glm_mtbs1)]

map_dfc(mods_glm_mtbs2, ~ names(.$aic[1:5])) %>% 
  kable(caption = "5 best transformations at each step")
best_aic_by_step <- map_dbl(mods_glm_mtbs2, ~.$aic[1])

best_aic_by_step <- c(step0 = mods_glm_mtbs1$step1$aic[['convert_none']], 
                      best_aic_by_step)
# AIC improvement by step
diff(best_aic_by_step)
plot(y = best_aic_by_step, 
     x = 1:length(best_aic_by_step) - 1,
     ylab = "AIC",
     xlab = "Number of variables transformed")

```

Best transformation each step.

```{r}
var_transformed <- map(mods_glm_mtbs2, function(x) x$var_transformed)
var_transformed
```


### same model for all response variables

Response variables are the proportion of years in which fires occurred.
Using best model formula selected in the previous step

```{r fit_glm1, dependson='iterate_transform'}



#best_form <- "~ poly(afgAGB,2)+ I(afgAGB^2):MAT + I(afgAGB^2):prcpPropSum +  poly(pfgAGB,2) + shrCover + MAT:I(MAP^2) + poly(MAP,2) + prcpPropSum*MAT + I(pfgAGB^2):prcpPropSum"

# best_form <- "~ poly(afgAGB,2)+ I(afgAGB^2):prcpPropSum +  poly(pfgAGB,2) + shrCover  + poly(MAP,2)  + I(pfgAGB^2):prcpPropSum + MAT"
# 
# best_form <- "~ poly(afgAGB,2)+ I(afgAGB^2):prcpPropSum +  poly(pfgAGB,2) + shrCover + MAT:I(MAP^2) + poly(MAP,2) + I(pfgAGB^2):prcpPropSum"
# 
# best_form <- "~ poly(afgAGB,2)+ I(afgAGB^2):prcpPropSum +  poly(pfgAGB,2) + shrCover + MAT:I(MAP^2) + poly(MAP,2) + I(pfgAGB^2):prcpPropSum + prcpPropSum"

# this is the formula we used at the end of the denver meeting

#best_form <- "~ poly(afgAGB,2) + poly(pfgAGB,2) + shrCover + MAT + poly(MAP,2) + prcpPropSum"


best_form <- mods_glm_mtbs1$final_formula %>% 
  str_replace(".+(?=~)", "") # remove everything before ~ (i.e. response var)
forms_glm1 <-  map(paste(vars_prop, best_form), as.formula)

print(best_form)
names(forms_glm1) <- names(vars_occur)
mod_glm1 <- map(method, function(x) {
  # fitting glms for each formula 
  map(forms_glm1, function(form) {
    glm(form, data = dfs_train[[x]], family = 'binomial', weights = mtbs_n)
  })
}) 

# should be the same AIC (i.e. refitting the same model)
AIC(mod_glm1$paint$mtbs)

mod_glm1_flat <- flatten_rename(mod_glm1)
summary(mod_glm1_flat$paint_mtbs)

```

## partial dependence & VIP

```{r pdp_glm, warning = FALSE, fig.width = 8, fig.height=8, cache = TRUE, dependson='fit_glm1' , cache.lazy = FALSE}
# vip::vip(bin_glm1) # variable importance
vip_plots1 <- map2(mod_glm1_flat, names(mod_glm1_flat), function(mod, name) {
   out <- vip::vip(mod) +
    labs(subtitle = name)
})
marrangeGrob(vip_plots1, ncol = 3, nrow = 3)
map(mod_glm1_flat[1], pdp_all_vars, mod_vars = pred_vars, ylab = 'probability',
              train = train_pred)
```


## observed vs. predicted

Predicting on the data
Note now that dfs_train is the whole dataset, i'm predicting on the
'training' dataframe

```{r}

# create prediction for each each model
# (i.e. for each fire proporation variable)
predict_by_response <- function(mods, df) {
  df_out <- df
  for(var in names(vars_prop)) {
    mod <- mods[[var]]
    
    response_name <- paste0(vars_prop[[var]], "_pred")
    df_out[[response_name]] <- predict(mod, df, type = 'response')
  }
  df_out
}

pred_glm1 <- map2(mod_glm1, dfs_train, predict_by_response)

dfs_test_warm <- map(dfs_train, function(df) mutate(df, MAT = MAT + 5))

pred_glm1_warm <- map2(mod_glm1, dfs_test_warm, predict_by_response)
```

```{r message = FALSE}

# long format so can have observed and predicted columns
pred_glm1_long <- map(pred_glm1, function(df) { 
  df %>% 
    select(matches("_prop")) %>% 
    mutate(row = 1:n()) %>% 
    pivot_longer(cols = -row) %>% 
    mutate(data_source = str_extract(name, "^[a-z]+"),
           type = ifelse(str_detect(name, "prop_pred$"), 'predicted', 
                         'observed')) %>% 
    select(-name) %>% 
    pivot_wider(id_cols = c('row', 'data_source'), 
                names_from = 'type',
                values_from = 'value') %>% 
    select(-row)
})

# observed vs predicted ggplots
g <- ggplot(pred_glm1_long[[1]] %>% filter(observed <= 0.1), 
            aes(y = predicted)) +
  facet_wrap(~data_source) +
  labs(subtitle = 'observed and predicted fire probabilities',
       y = "predicted probability")

g +
  geom_boxplot(aes(x = as.factor(as.numeric(as.factor(observed)) - 1)))+
  labs(x = "number of observed fires")

g +
  geom_jitter(aes(x = observed), width = 0.005, alpha = 0.1) +
  geom_smooth(aes(x = observed), method = 'lm') +
  geom_abline(slope = 1) 

```

### Deciles

Binning predictor variables into deciles (actually 0.5 percentiles) and looking at the mean
predicted probability for each decile.

Then predicting on an identical dataset but with warming

```{r}
vars_prop_pred <- paste0(vars_prop, "_pred")
response_vars <- c(vars_prop, vars_prop_pred)

pred_glm1_deciles <- map(pred_glm1, predvars2deciles, 
                         response_vars = response_vars,
                         pred_vars = pred_vars)

pred_glm1_deciles_warm <- map(pred_glm1_warm, predvars2deciles,
                              response_vars = response_vars,
                              pred_vars = pred_vars)

map2(pred_glm1_deciles, names(pred_glm1_deciles), function(df, method) {
  map(vars_prop, decile_dotplot, df = df, method = method, 
      add_predicted = TRUE)
})

# tryng
map2(pred_glm1_deciles_warm, names(pred_glm1_deciles_warm), function(df, method) {
  map(vars_prop, decile_dotplot, df = df, method = method, 
      add_predicted = TRUE, title = "data w/ +5 deg C warming")
})

```

Plot observed vs predicted values for the quantile

```{r}
# long format, so have columns of predicted and observed
# and can facet by response variable
dfs_obs_v_pred <- map(pred_glm1_deciles, function(df) {
  df %>% 
    select(matches("_prop")) %>% 
    mutate(id = 1:nrow(.)) %>% 
    pivot_longer(cols = matches("_prop")) %>% 
    mutate(type = ifelse(str_detect(name, "_pred$"),
                         "predicted", "observed"),
           variable = str_extract(name, "^[a-z]+")) %>% 
    pivot_wider(id_cols = c(id, variable), names_from = 'type')
})     

map2(dfs_obs_v_pred, names(dfs_obs_v_pred), function(df, method) {
  ggplot(df, aes(observed, predicted)) +
    geom_point() +
    facet_wrap(~variable) +
    geom_abline(slope = 1) +
    labs(title = paste(method, "method"),
         subtitle = "fire probability averaged for each decile of each predictor variable",
         caption = "each panel shows observed and predicted values
         of annual fire probability, for a given fire dataset")
})

```

### Deciles Filtered 

Filtered 'Decile' plots of data. These plots show each vegetation variable,
but only based on data that falls into the upper and lower two deciles of
each climate variable. 


```{r glm_deciles_filtered, fig.height = 6}

pred_glm1_deciles_filt <- map(pred_glm1, predvars2deciles, 
                         response_vars = response_vars,
                         pred_vars = pred_vars,
                         filter_var = TRUE)

pred_glm1_deciles_warm <- map(pred_glm1_warm, predvars2deciles,
                              response_vars = response_vars,
                              pred_vars = pred_vars)

map2(pred_glm1_deciles_filt, names(pred_glm1_deciles_filt), function(df, method) {
  map(vars_prop, decile_dotplot_filtered, df = df, method = method)
})

```



# GNMs

Fitting models where afgAGB is non-linear,
and has the form -exp(Beta*afgAGB), where beta should be negative
so this forms a saturating relationship:

$$logit(p)=\beta_0-e^{\beta_1*afgAGB}+other\ linear\ terms$$

## Fitting models

### is a non-linear term better?

Fitting the model, with all linear terms except afgAGB is a negative exponential
term. (-exp(beta1*x))

Based on AIC the non-linear term makes the model way better

```{r gnm_best_transform, dependson='train', cache=TRUE}

afgNonLin <- function(afgAGB){
    list(predictors = list(beta1 = 1),
         variables = list(substitute(afgAGB)),
         term = function(predLabels, varLabels) {
             sprintf("-1*exp(%s*%s)",
                     predLabels[1], varLabels[1])
         })
}
class(afgNonLin) <- "nonlin"

set.seed(123)

# fitting all linear terms (i.e. this just the glm)
bin_gnm0 <- gnm(mtbs_prop ~ 
                  afgAGB + I(afgAGB^2) 
                + pfgAGB + I(pfgAGB^2)
                + MAT + I(MAT^2) 
                + MAP + I(MAP^2) + prcpPropSum,
                weight = mtbs_n, family = binomial(link = "logit"), 
                data = dfs_train$paint)

# afgAGB is non-linear
bin_gnm2 <- gnm(mtbs_prop ~ afgNonLin(afgAGB)
                + pfgAGB + I(pfgAGB^2)
                + MAT + I(MAT^2) 
                + MAP + I(MAP^2) + prcpPropSum, 
                weight = mtbs_n, family = binomial(link = "logit"), 
                data = dfs_train$paint,
                start = c(NA, -0.1, rep(NA, 7)))

AIC(bin_gnm0) # all 'linear terms'--i.e. best glm model
as.numeric(AIC(bin_gnm2)) # afgAGB is non linear (better model)

```


### Fitting various transforms

Holding the transform for afgAGB constant, but trying various transforms
for the other variables (they are still linear terms in the models
as in the GLMS above)

Fitting on a subset of the data b/ fitting these would take super long
for the full dataset

Trying a higher delta AIC to reduce the spurious transforms. Note that this
means that MAT doesn't get transformed (which it does with a low AIC value).
But it gets transformed to exp(MAT), which leads to weird threshold
type behavior in the model that doesn't seem right


```{r gnm_iterate_transform,message=FALSE, cache=TRUE, results='hide'}
set.seed(1234)
dfs_train_gnm <- map(dfs_biome3, function(df) {
  df[sample(1:nrow(df), 100000), ]
})
pred_vars_gnm <- pred_vars

# manually choosing the nonlinear form of afgAGB ( -e^(beta*afgAGB))
pred_vars_gnm['afgAGB'] <- 'afgNonLin(afgAGB)'

mods_gnm_mtbs1 <- glms_iterate_transforms(
  preds = pred_vars_gnm, 
  df = dfs_train_gnm$paint,
  response_var = "mtbs_prop", 
  delta_aic = 15,
  fit_mod = fit_bin_gnms)

```


```{r }
best_form_gnm1 <- mods_gnm_mtbs1$final_formula
best_form_gnm1
best_form_gnm2 <- replace_poly(best_form_gnm1, keep_response = FALSE)
best_form_gnm2 

```


### same model for all response variables

Response variables are the proportion of years in which fires occurred.
Using best model formula selected in the previous step

```{r fit_gnm1, dependson='gnm_iterate_transform', cache=TRUE,message=FALSE, results='hide'}
forms_gnm1 <-  map(paste(vars_prop, "~",  best_form_gnm2), as.formula)

names(forms_gnm1) <- names(vars_occur)

n_other_vars <- str_count(best_form_gnm2, "\\+")

# providing start value for non-linear term (based on testing
# by only including afgAGB in the model)
start <- c(NA, -0.2, rep(NA, n_other_vars))
mod_gnm1 <- map(method, function(x) {
  # fitting glms for each formula 
  map(forms_gnm1, function(form) {
    gnm(form, data = dfs_train[[x]], family = 'binomial', 
        weights = mtbs_n,
        start = start)
  })
})
```


```{r}
mod_gnm1_flat <- flatten_rename(mod_gnm1)
summary(mod_gnm1_flat$paint_mtbs)

```

## Partial dependence plots 

variable importance plots didn't work with the gnm model objects

```{r pdp_gnm, warning = FALSE, fig.width = 8, fig.height=8, cache = TRUE, dependson='fit_gnm1'}
map(mod_gnm1_flat, pdp_all_vars, mod_vars = pred_vars, ylab = 'probability',
              train = train_pred)
```

## observed vs. predicted

Predicting on the data, for each model, and then again 
on the data with 5 degrees added to MAT

```{r}
pred_gnm1 <- map2(mod_gnm1, dfs_train, predict_by_response)

pred_gnm1_warm <- map2(mod_gnm1, dfs_test_warm, predict_by_response)

```



### Deciles

Binning predictor variables into deciles and looking at the mean
predicted probability for each decile.

Then predicting on an identical dataset but with + 5C warmed MAT

```{r gnm_deciles}

pred_gnm1_deciles <- map(pred_gnm1, predvars2deciles, 
                         response_vars = response_vars,
                         pred_vars = pred_vars)

pred_gnm1_deciles_warm <- map(pred_gnm1_warm, predvars2deciles, 
                         response_vars = response_vars,
                         pred_vars = pred_vars)

map2(pred_gnm1_deciles, names(pred_gnm1_deciles), function(df, method) {
  map(vars_prop, decile_dotplot, df = df, method = method, 
      add_predicted = TRUE)
})

# same but with + 5 degrees of warming
map2(pred_gnm1_deciles_warm, names(pred_gnm1_deciles_warm), function(df, method) {
  map(vars_prop, decile_dotplot, df = df, method = method, 
      add_predicted = TRUE, title = "data w/ +5 deg C warming")
})

```


### Deciles Filtered 

Filtered 'Decile' plots of data. These plots show each vegetation variable,
but only based on data that falls into the upper and lower two deciles of
each climate variable. 


```{r gnm_deciles_filtered, fig.height = 6}

pred_gnm1_deciles_filt <- map(pred_gnm1, predvars2deciles, 
                         response_vars = response_vars,
                         pred_vars = pred_vars,
                         filter_var = TRUE)

pred_gnm1_deciles_warm <- map(pred_gnm1_warm, predvars2deciles,
                              response_vars = response_vars,
                              pred_vars = pred_vars)

map2(pred_gnm1_deciles_filt, names(pred_gnm1_deciles_filt), function(df, method) {
  map(vars_prop, decile_dotplot_filtered, df = df, method = method)
})

```


# Save output

```{r save_output}
# glm models
mods2save <- mod_glm1_flat
mods2save$formula <- best_form
saveRDS(mods2save, "models/glm_binomial_models_v1_no-shrCover.RDS")

mods2save_gnm <- mod_gnm1_flat
mods2save_gnm$formula <- best_form_gnm1
saveRDS(mods2save_gnm, "models/gnm_binomial_models_v1_no-shrCover.RDS")
```

