---
title: "Models of Pastick et al. (2021) fire probability"
author: "Martin Holdrege"
date: "`r lubridate::today()`"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Dependencies 

Sourcing the script that creates a dataframe of historical
fire probability (from Pastick et al), as well as biotic and climate
predictors for those same grid-cells. 

```{r warning=FALSE, message=FALSE, cache = TRUE}
source("scripts/04_create_pastick_fire-prob_dataframe.R")
```

```{r warning=FALSE, message=FALSE}
source("src/general_functions.R")
source("src/fig_params.R")
library(randomForest)
library(tidyverse)
library(margins) # for cplot()
library(GGally) # for ggpairs()
library(gnm) # generalized non-linear models
```

## functions 

```{r}

# create conditional predicted plots (margins package),
# create plot for each predictor variable in the model. 
cplot_all_vars <- function(mod, ...) {
  mod_vars <- attributes(terms(mod))[["term.labels"]] %>% 
     # not including interactions or squared terms
    # e.g. I(x^2)
    str_subset(":|(^I\\()", negate = TRUE)
  
  for (var in mod_vars){
    print(cplot(mod, var, ...))
  }
}
```

# Prep data

```{r prep_data}

thresh_agb <- 500 # aboveground biomass threshold

df_past3 <- df_past2 %>% 
  rename(fireProbPerc = fireProb) %>%  # fireProb is a %
  mutate(fireProb = fireProbPerc/100) %>%  # actually probability (between 0 and 1)
  # probability of fire in a given year
  mutate(fireProbYr = calc_yearly_prob(fireProb, n = 35),
          # number of years the mtbs count data corresponds to (for binomial glm)
         # all count datasets (mtbs and ifph) are 35 years (change if updated)
         mtbs_n = 35, 
         # proportion of years with fires
         mtbs_prop = nfire_mtbs/mtbs_n,
         # logical of whether a fire occured
         mtbs_occur = nfire_mtbs > 0, 
         mtbs_occur = factor(mtbs_occur, levels = c("TRUE", "FALSE")),
         ifph_prop = nfire_ifph/mtbs_n,
         comb_prop = nfire_comb/mtbs_n) %>% 
  # for now restricting data at the extreme ends
  # which is far outside the range of what stepwat would model. 
  filter(afgAGB < thresh_agb, pfgAGB < thresh_agb)

```

## training data

Using a small sample for now to make model fitting quicker

```{r}
pred_vars <- names(df_past3) %>% 
  str_subset("(AGB)|(Cover)|(Summer)|(Spring)|(Yearly)")

n = 10000
train <- slice_sample(df_past3, n = n) %>% 
  as.data.frame()
```

# Exploratory figs & summary values

Note that the fsim_bp dataset has a mean fire probability around 0.6%.


```{r}
df_past3 %>% 
  select(-mtbs_occur) %>% 
  pivot_longer(cols = everything(),
               names_to = 'variable') %>% 
  group_by(variable) %>% 
  summarise(across(value, .fns = list(mean = mean, min = min, 
                                      median = median, max = max))) %>% 
  mutate(across(where(is.numeric), round, 4)) %>% 
  knitr::kable(caption = 'summaries of variables')

```

Plot each predictor variable against fireProbYr

```{r fig.height=9, fig.width=8}

par(mfrow = c(2, 2))
for (var in pred_vars) {
  form <- as.formula(paste0('fireProbYr ~', var))
  mod <- lm(form, data = train)
  plot(formula = form, data = train, ylab = lab_fireProb[['fireProbYr']],
       xlab = var)
  abline(mod)
}
  

```

## Histograms

For all histograms data includes all grid cells from Pastick et al.,
except cells with annual or perennial forb & grass biomass > `r thresh_agb`
were excluded.

```{r message = FALSE, warning = FALSE, fig.height = 9}
g <- ggplot(df_past3) +
  # note the mtbs fir prop goes up to >20%, but they're 
  # are very few cells with that many fires, so truncating
  coord_cartesian(c(0, 10)) +
  labs(x = "Fire probability (%/year)") +
  theme_classic()

h1 <- g +
  geom_histogram(aes(x = fireProbYr*100)) +
  labs(subtitle = "Pastick et al modelled data")

h2 <- g +
  geom_histogram(aes(mtbs_prop*100)) +
  labs(subtitle = "MTBS, fire occurence over 35 years,\n(some outliers not shown)")


h3 <- g +
  geom_histogram(aes(fsim_bp*100))+
  labs(subtitle = "FSim modelled data")

h4 <- g +
  geom_histogram(aes(mtbs_prop*100)) +
  labs(subtitle = "MTBS, fire occurence over 35 years,\n(all data shown--some bars to small to see)") +
  coord_cartesian(xlim = range(df_past3$mtbs_prop)*100)

h5 <- g +
  geom_histogram(aes(ifph_prop*100)) +
  labs(subtitle = "IFPH, fire occurence over 35 years,\n(some outliers not shown)")

h6 <- g +
  geom_histogram(aes(comb_prop*100)) +
  labs(subtitle = "IFPH and MTBS combined, fire occurence over 35 years,\n(some outliers not shown)")

gridExtra::grid.arrange(h1, h2, h3, h4, h5, h6, ncol = 2)

```

## comparing response variables

```{r}
plot(train$fireProbYr*100, train$fsim_bp*100,
     xlab = "Fire probability (%) Pastick et al.",
     ylab = "Fire probability (%) FSim model data")
abline(0, 1)


response_vars <- names(df_past3) %>% 
  str_subset("(fireProbYr)|(fsim_bp)|(_prop$)")

ggpairs(train , 'correlogram between response variables',
        columns = response_vars,
        lower = list(continuous = GGally::wrap("points", alpha = 0.1,    size=0.2)))
```



# Random forest


## Fit Model


```{r}
# model formula with all predictor vars
form_fireProb  <- as.formula(
  paste('fireProb ~', paste(pred_vars, collapse = "+"))
)

# yearly, probability of fire
form_fireProbYr  <- as.formula(
  paste('fireProbYr ~', paste(pred_vars, collapse = "+"))
)

# fire occurence (0/1) in MTBS data, over 35 years
form_mtbsOccur <-  as.formula(
  paste('mtbs_occur ~', paste(pred_vars, collapse = "+"))
)

forms <- list(fireProb = form_fireProb,
              fireProbYr = form_fireProbYr,
              mtbsOccur = form_mtbsOccur )

mod_names <- names(forms)

rf_mods <- map(forms, randomForest, ntree = 100, data = train,
               nodesize = 10)

rf_mods

```

## Variable importance

```{r results='hide', fig.keep='all'}

# variable importance
rf_import <- map(rf_mods, function(x) {
  importance(x) %>% 
    as_tibble(rownames = 'var') 
})

map2(rf_mods, mod_names, function(x, y) {
  print(varImpPlot(x = x, main = y))
})

```

## Partial dependence plots

9 most important variables. For the case of MTBS fire occurrence 
data the output is transformed to yearly fire probability. 

```{r fig.height=9, fig.width = 8, cache = TRUE}


for (j in seq_along(rf_mods)) {
  vars <- rf_import[[j]]$var[1:9] # 9 most important variables
  name <- mod_names[[j]]
  print(name)
  par(mfrow = c(3, 3))
  for (i in seq_along(vars)) {
    out <- partialPlot(rf_mods[[j]], pred.data = train, x.var = vars[i],
                       plot = FALSE)
    
    if(rf_mods[[j]]$type == "classification") {
      out$y = exp(out$y)/(1 + exp(out$y)) # get probability from logit
      # convert to probability of fire in a given year
      out$y <- calc_yearly_prob(out$y, n = 35)
    }
    
    plot(out, xlab = vars[i], main = NULL, ylab = lab_fireProb[[name]],
         type = 'l')
  }
  mtext(name, outer = TRUE)
}

```


## Examine Model fit

```{r}
name <- 'fireProbYr'
hist(df_past3$fireProbYr, xlab = lab_fireProb[[name]],
     main = 'Data from all grid-cells')

train2 <- train
train2$pred <- predict(rf_mods[[name]]) # this the oob prediction

train2$resid <- train2[[name]] - train2$pred
plot(train2[[name]], train2$pred, ylab = "Predicted", xlab = 'Observed',
     main = lab_fireProb[[name]])
abline(0, 1)
plot(train2$pred, train2$resid,
     ylab = "Predicted", xlab = 'Residual',
     main = lab_fireProb[[name]])

```

# GLM (Pastick fire data)

## fitting model

```{r}
n_glm = 10000
train_glm <- slice_sample(df_past3, n = n_glm) %>% 
  as.data.frame()

gau_glm1 <- glm(fireProbYr ~ afgAGB + pfgAGB +  shrCover + prcpYearly +
                  tmaxSummer + prcpSummer +afgAGB:prcpSummer +
                  pfgAGB:prcpSummer, data = train_glm,
                family = gaussian(link = 'logit'))


summary(gau_glm1)

# R squared
var_explained(gau_glm1)
```

## Examine model fit

```{r}
train_glm2 <- train_glm
train_glm2$pred <- predict(gau_glm1, type = 'response')

train_glm2$resid <- train_glm2$pred - train_glm2$fireProbYr 

plot(train_glm2$fireProbYr, train_glm2$pred, xlab = 'observed',
     ylab = 'predicted')
abline(0, 1)

plot(train_glm2$pred, train_glm2$resid,  xlab = 'predicted', ylab = 'residual')
abline(0, 0)
```

## Marginal effects plots

```{r results='hide', fig.keep='all'}
cplot_all_vars(gau_glm1)
```




# GLM -- MTBS

Here the response variable is the number of fires observed per pixel
(check file name for year range, but initially using 35 years, 1985-2019)



## Null model

```{r}
mtbs_null <- glm(mtbs_prop ~ 1, weight = mtbs_n, family = binomial,
                 data = train_glm)
summary(mtbs_null)
mtbs_mean_prob <- predict(mtbs_null, type = 'response') %>% 
  mean()

mtbs_mean_prob

```

The mean probability of fire in any given year based on mtbs data is 
`r round(mtbs_mean_prob*100, 2)`%. 

## full(ish) model

```{r}

train_glm_bin <- train_glm
bin_glm1 <- glm(mtbs_prop ~ afgAGB + pfgAGB +  shrCover + prcpYearly +
                  tmaxSummer + prcpSummer
                # interactions
                  +afgAGB:prcpSummer + pfgAGB:prcpSummer,
                weight = mtbs_n, family = binomial(link = "logit"), data = train_glm)
summary(bin_glm1)
# diagnostic plots
plot(bin_glm1)
pred<- predict(bin_glm1, type = 'response')

plot(train_glm2$pred, pred,
     xlab = "Predicted fire probability, gaussian glm, Pastick data",
     ylab = "Predicted fire probability, binomial glm, mtbs data",
     main = 'comparing models beween datasets')
abline(0, 1)

car::residualPlots(bin_glm1)


```

## NLS model

### testing with fake data

Continue here--

```{r}
n = 1000
df <- tibble(
  x1 = rnorm(n, 5),
  x2 = runif(n),
  
  y = 1 - exp(-1.5*x1)  + 0.01*x2,
  y3 = y  + rnorm(n, 0, 0.001) # adding noise for testing w/ nls
)
df$y2 <- as.numeric(df$y > mean(df$y)) # creating a binary outcome

plot(y~x1, data = df)

mod <- gnm(y ~ 1  + Const(-1)Exp(x1) + x2, data = df)
mod
yhat <- predict(mod)
plot(df$y, yhat)
nls_mod <- nls(y3 ~ int + a*x1^b + c*x2,
               data = df,
               start = list(int = 1, a = 1, b = -1, c= 1))
summary(nls_mod)
yhat <- predict(nls_mod)
plot(df$y, yhat)
abline(0, 1)
```


Continue working on this...

```{r}
#
```


## Marginal effects plots

```{r results='hide', fig.keep='all'}
# variables in the model
cplot_all_vars(bin_glm1)
```

# GLM--IFPH

## full(ish) model

```{r}

ifph_glm1 <- glm(ifph_prop ~ afgAGB + pfgAGB +  shrCover + prcpYearly +
                  tmaxSummer + prcpSummer
                # interactions
                  +afgAGB:prcpSummer + pfgAGB:prcpSummer,
                weight = mtbs_n, family = binomial, data = train_glm)

# diagnostic plots
plot(ifph_glm1)
pred_ifph <- predict(ifph_glm1, type = 'response')

plot(pred, pred_ifph,
     xlab = "Predicted fire probability, binomial glm, MTBS data",
     ylab = "Predicted fire probability, binomial glm, IFPH data",
     main = 'comparing models beween datasets')
abline(0, 1)

car::residualPlots(ifph_glm1)

```


## Marginal plots

```{r results='hide', fig.keep='all'}
cplot_all_vars(ifph_glm1)
car::marginalModelPlots(ifph_glm1)
```

